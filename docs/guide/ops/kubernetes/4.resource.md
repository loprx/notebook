---
title: 资源调度
order: 4
---

# 资源调度

## Label & Selector
在Kubernetes中，Label是键值对形式的元数据，可以附加到各种资源对象上，比如Pod、Service、Deployment等。这些Label可以用来对资源对象进行分类、组织和标记，从而方便管理和操作。

Label Selector则是一种查询语法，用于根据Label的键值对来选择匹配的资源对象。它可以在各种场景下使用，比如查找特定类型的Pod、服务发现、负载均衡等。通过Label Selector，可以方便地根据需要选择和操作资源对象，实现灵活的资源管理和控制。

### 命令
```shell
# 创建临时label，永久修改可以通过edit
kubectl label po <po> app=hello -n <ns>

# 获取label
kubectl label po--show-labels

# 根据标签去匹配pod
kubectl get po -l type=app
kubectl get po -l 'version in (1.1.0, 1.0.0)'
kubectl get po -l version!=1.1.0,type=app
# 使用逻辑运算符 OR：
kubectl get pods -l 'key1=value1' -o 'key2=value2'

```

### 基本操作
Label Selector 通常由以下几种表达式组成：

1. 等式（Equality）： 使用等式操作符（=）来匹配指定键值对的标签。例如，app=nginx 表示选择具有标签 app，其值为 nginx 的资源对象。
2. 集合匹配（Set-based Matching）： 使用集合操作符（in、notin、exists、does not exist）来匹配指定标签的值。例如，environment in (production, staging) 表示选择具有标签 environment，其值为 production 或 staging 的资源对象。
3. 按键过滤（Key Filtering）： 使用键过滤操作符（!=、!）来匹配指定键的资源对象。例如，app!=nginx 表示选择具有标签 app，但其值不为 nginx 的资源对象。
4. 逻辑运算（Logical Operators）： 使用逻辑操作符（AND、OR、NOT）来组合多个标签选择器。例如，app=nginx, environment=production 表示选择具有标签 app 值为 nginx 且具有标签 environment 值为 production 的资源对象。

以下是一些使用 Label Selector 的示例：

+ 选择具有标签 app=nginx 的 Pod：

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
  labels:
    app: nginx
```

+ 选择具有标签 environment 值为 production 或 staging 的 Service：

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx
    environment: 
      in: [production, staging]
```

+ 选择具有标签 tier 值为 backend 但没有标签 app 的 Deployment：

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend-deployment
spec:
  selector:
    matchLabels:
      tier: backend
  matchExpressions:
  - {key: app, operator: DoesNotExist}
```

## Deployment
在 Kubernetes 中，Deployment、ReplicaSet（简称 RS）和 Pod 之间存在一种关系，它们通常是这样关联的：

1. Deployment：Deployment 是一个高级别的资源对象，用于管理应用程序的部署和更新。它负责定义所需的 Pod 模板和副本数目，并控制 RS 的创建、更新和删除过程。
2. ReplicaSet：ReplicaSet 是一个控制器对象，用于确保指定数量的 Pod 副本在集群中运行。Deployment 通常会创建一个或多个 ReplicaSet，并使用 ReplicaSet 来管理 Pod 的生命周期。当 Deployment 进行滚动更新或扩缩容时，它会通过创建新的 ReplicaSet、逐步删除旧的 ReplicaSet 来实现更新和调整副本数目。
3. Pod：Pod 是 Kubernetes 中最小的部署单元，它可以包含一个或多个容器，并共享相同的网络命名空间、存储卷和 IP 地址。ReplicaSet 负责创建和管理一组相同配置的 Pod 副本，确保它们按照预期的副本数目运行在集群中。

简单来说，Deployment 使用 ReplicaSet 来管理 Pod 的副本数目和生命周期。当需要更新应用程序时，Deployment 会创建一个新的 ReplicaSet，并逐步替换旧的 ReplicaSet 中的 Pod。这种方式可以实现应用程序的滚动更新，并保证在更新过程中不会中断服务。

### 创建
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment  # 部署的名称
spec:
  replicas: 3  # 副本数
  selector:
    matchLabels:
      app: nginx  # 选择器，用于选择部署的 Pod
  strategy:
    type: RollingUpdate  # 滚动更新策略类型
    rollingUpdate:
      maxSurge: 1  # 最大超出副本数
      maxUnavailable: 1  # 最大不可用副本数
  template:  # Pod 模板
    metadata:
      labels:
        app: nginx  # Pod 的标签
    spec:
      containers:
      - name: nginx
        image: nginx:latest  # 使用的镜像
        ports:
        - containerPort: 80  # 容器监听端口
  revisionHistoryLimit: 5  # 保留的历史版本数量

```

### 滚动更新
滚动更新是 Kubernetes 中一种更新 Deployment 的策略，它允许你在不中断服务的情况下逐步更新应用程序的实例。滚动更新的步骤如下：

1. Kubernetes 更新 Deployment 的 Pod 模板：通过修改 Deployment 中的 Pod 模板，例如更改容器的镜像版本或配置。
2. Kubernetes 创建新的 ReplicaSet：一旦 Deployment 的 Pod 模板被更新，Kubernetes 将创建一个新的 ReplicaSet，该 ReplicaSet 包含根据新 Pod 模板创建的 Pod。
3. Kubernetes 逐步调整实例数：Kubernetes 会逐步增加新 ReplicaSet 中 Pod 的数量，同时减少旧 ReplicaSet 中 Pod 的数量，以确保整个应用程序的实例数保持稳定。这确保了在更新期间服务的稳定性。
4. Kubernetes 删除旧的 ReplicaSet：一旦新 ReplicaSet 中的 Pod 数量达到预期数量，并且旧 ReplicaSet 中的 Pod 数量减少到零，Kubernetes 将删除旧 ReplicaSet。

查看滚动更新信息

```shell
kubectl rollout status deploy nginx-deployment
```

### 回滚
要回滚 Kubernetes 中的 Deployment，你可以使用以下命令：

```shell
kubectl rollout undo deployment <deployment-name>
```

这会将指定 Deployment 的当前版本回滚到之前的版本。Kubernetes 会自动处理回滚，并且在回滚完成后，新的 Pod 会逐步替换掉旧的 Pod，直到回滚完成。

你也可以使用 --to-revision 标志来指定要回滚到的特定版本，例如：

```shell
kubectl rollout undo deployment <deployment-name> --to-revision=<revision>
```

这将指定 Deployment 回滚到指定的修订版本号。

回滚完成后，你可以使用以下命令查看回滚历史：

```shell
kubectl rollout history deployment <deployment-name>
```

### 扩容和缩容
1. 扩容： 使用以下命令将 Deployment 扩容到指定的副本数量：

```shell
kubectl scale deployment <deployment-name> --replicas=<desired-replicas>
```

其中，`<deployment-name>` 是要扩容的 Deployment 的名称，`<desired-replicas>` 是要设置的目标副本数量。

2. 缩容： 使用以下命令将 Deployment 缩容到指定的副本数量：

```shell
kubectl scale deployment <deployment-name> --replicas=<desired-replicas>
```

同样地，`<deployment-name>` 是要缩容的 Deployment 的名称，`<desired-replicas>` 是要设置的目标副本数量。

### 暂停与恢复
```shell
kubectl rollout pause deployment <deployment-name>
```

```shell
kubectl rollout resume deployment <deployment-name>
```

## StatefulSet
StatefulSet 是 Kubernetes 中用于管理有状态应用程序的控制器。与 Deployment 不同，StatefulSet 给每个 Pod 分配一个稳定的标识符（通常是序号），并确保每个 Pod 的网络标识符、存储和其他属性在 Pod 重启和迁移时保持不变。

StatefulSet 主要用于运行需要持久化存储或唯一网络标识符的应用程序，如数据库（例如 MySQL、PostgreSQL）、分布式消息队列（例如 Kafka）或其他需要唯一标识符的应用程序。

StatefulSet 与 Deployment 相似，但有几个关键区别：

1. Pod 的名称：StatefulSet 控制的 Pod 的名称包含了一个有序的索引，例如 pod-name-0、pod-name-1 等。
2. 稳定标识符：StatefulSet 为每个 Pod 提供一个唯一的稳定标识符，如 hostname。
3. 网络标识符：StatefulSet 为每个 Pod 提供一个唯一的网络标识符，可用于服务发现和 DNS 查询。
4. 持久化标识符：StatefulSet 支持动态卷配置，可以确保每个 Pod 在重启和迁移时都能够保留相同的持久化存储。

StatefulSet 在需要管理有状态应用程序的场景下非常有用，它确保了应用程序的稳定性和可靠性，并提供了对有状态应用程序的良好支持。

### 定义
```yaml
apiVersion: apps/v1  # 使用的 Kubernetes API 版本
kind: StatefulSet  # 定义的 Kubernetes 资源类型
metadata:
  name: example-statefulset  # StatefulSet 的名称
spec:
  replicas: 3  # 副本数量
  serviceName: "example-service"  # 关联的服务名称
  selector:  # 选择器，用于匹配 Pod
    matchLabels:  # 匹配的标签
      app: example  # app 标签的值为 example
  template:  # Pod 模板
    metadata:
      labels:
        app: example  # Pod 的标签
    spec:  # Pod 的规格
      containers:  # 容器列表
      - name: nginx  # 容器名称
        image: nginx:1.7.9  # 容器使用的镜像
        ports:  # 容器暴露的端口
        - containerPort: 80  # 端口号为 80
          name: web  # 端口名称为 web
        volumeMounts:  # 挂载的卷
        - name: www  # 卷的名称
          mountPath: /usr/share/nginx/html/  # 挂载路径
  volumeClaimTemplates:  # 卷声明模板
  - metadata:
      name: www  # 卷声明的名称
      annotations:  # 注释
        volume.alpha.kubernetes.io/storage-class: anything  # 存储类注释
    spec:  # 卷声明的规格
      accessModes: ["ReadWriteOnce"]  # 访问模式
      resources:  # 资源请求
        requests:
          storage: 1Gi  # 存储容量
```

### 扩容缩容与滚动更新
会按顺序更新

更新image需要通过patch命令

### 发布与删除
1. 灰度发布：
    - 通过逐步更新 StatefulSet 中的 Pod 实例来实现灰度发布。您可以先更新一部分 Pod，然后观察它们的行为，如果没有问题，则继续更新其他 Pod。
    - 您可以使用 StatefulSet 的 updateStrategy 字段来控制 Pod 的更新策略，例如 OnDelete 策略会等待所有 Pod 删除后再更新，而 RollingUpdate 策略会逐步更新 Pod。
2. 金丝雀发布：
    - 类似于灰度发布，您可以先更新一小部分 Pod 实例，然后观察它们的行为和性能。如果一切正常，可以逐步增加更新的 Pod 实例数量。
    - 使用 StatefulSet 的 updateStrategy 字段，结合适当的标签选择器和选择条件，可以实现金丝雀发布。通过逐步更新匹配特定标签的 Pod 实例，您可以控制新版本的逐步部署。



1. Partition 属性：Partition 属性是 StatefulSet 对象的一个字段，它确定了更新时受影响的 Pod 子集。当您将 partition 属性设置为一个非零值时，StatefulSet 将只更新具有比该值小的索引的 Pod。这允许您以分批的方式更新 Pod，从而实现灰度发布。
2. 灰度发布策略：通过逐步增加 partition 的值，您可以控制更新的 Pod 数量。例如，将 partition 设置为 1 将更新索引小于 1 的 Pod，将 partition 设置为 2 将更新索引小于 2 的 Pod，依此类推。逐步增加 partition 可以逐步扩大更新范围，实现灰度发布。
3. 全部更新：如果您希望更新全部的 Pod，可以将 partition 属性设置为 0，这将影响所有 Pod 并触发它们的滚动更新。

#### onDelete
onDelete 策略类型：onDelete 策略有两种类型：

+ Delete：表示在删除 StatefulSet 对象时，Pod 将被删除，并且 StatefulSet 控制器不会自动创建替代的 Pod。这意味着一旦删除了 StatefulSet，相关的 Pod 将被永久删除。
+ Orphan：表示在删除 StatefulSet 对象时，Pod 将被“放逐”而不是立即删除。被放逐的 Pod 不再受 StatefulSet 控制，但它们仍然存在于集群中。这允许您手动处理这些 Pod，例如将它们重新分配到其他控制器。

#### 级联删除与非级联删除
StatefulSet 的级联删除与非级联删除与一般资源的概念类似，但是有一些特定的注意事项：

1. 级联删除：
    - 在删除 StatefulSet 时，默认情况下会执行级联删除，这意味着与 StatefulSet 相关的所有 Pod 和持久卷声明 (PVC) 也会被删除。
    - 该操作将删除 StatefulSet 的所有实例，以及它们对应的网络标识符、持久化存储和其他相关资源。
    - 级联删除适用于在删除 StatefulSet 时希望清理所有相关资源的场景。
2. 非级联删除：
    - 非级联删除将仅删除 StatefulSet 本身，而不会影响与其相关的 Pod 和 PVC。
    - 这意味着 StatefulSet 的 Pod 将继续运行，并且与它们的网络标识符和持久化存储保持连接，即使 StatefulSet 自身已被删除。
    - 非级联删除通常用于确保 StatefulSet 的实例持续运行，即使 StatefulSet 资源本身不再存在。

在 Kubernetes 中，您可以通过在删除资源时设置 --cascade=false 选项来执行非级联删除，例如：

```bash
kubectl delete statefulset <statefulset-name> --cascade=false
```

### 主要命令
1. 创建 StatefulSet：

```bash
kubectl create -f <statefulset-definition.yaml>
```

2. 查看 StatefulSet：

```bash
kubectl get sts
```

3. 查看详细信息：

```bash
kubectl describe sts <statefulset-name>
```

4. 更新 StatefulSet：

```bash
kubectl apply -f <updated-statefulset-definition.yaml>
```

5. 删除 StatefulSet：

```bash
kubectl delete sts <statefulset-name>
```

6. 扩容或缩容：

```bash
kubectl scale sts <statefulset-name> --replicas=<new-replica-count>
```

7. 滚动更新：

```bash
kubectl rollout status sts <statefulset-name>
```

8. 回滚到先前的版本：

```bash
kubectl rollout undo sts <statefulset-name>
```

## DaemonSet
1. 每个节点一个 Pod：
    - DaemonSet 会在集群中的每个节点上创建一个 Pod 的副本，确保每个节点都运行指定的应用程序或服务。
    - 当有新的节点加入集群时，DaemonSet 会自动在新节点上创建 Pod，以确保集群中每个节点的运行环境都是一致的。
2. 滚动更新：
    - 类似于其他控制器，DaemonSet 支持滚动更新功能，可以在更新 DaemonSet 时逐步替换现有的 Pod 实例，以避免影响集群的稳定性。
3. 节点调度：
    - DaemonSet 可以根据节点的标签选择器来确定在哪些节点上运行 Pod 实例。
    - 通过节点选择器，可以灵活地控制 DaemonSet 在哪些节点上运行 Pod，从而满足不同节点的资源需求或特定的部署策略。
4. 应用场景：
    - DaemonSet 适用于需要在每个节点上运行的服务或应用程序，例如日志收集代理、监控代理、网络代理等。
    - 它还常用于在整个集群中部署辅助工具，如存储卷插件、容器网络插件等。
5. 自动调整：
    - 通过 Kubernetes 的自动调度和自愈机制，DaemonSet 可以确保在节点故障或不可用时自动重新调度 Pod 实例，以保证系统的高可用性和稳定性。

### 日志收集
Fluentd

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app: fluentd
  template:
    metadata:
      labels:
        app: fluentd
    spec:
      serviceAccount: fluentd
      containers:
      - name: fluentd
        image: agilestacks/fluentd-elasticsearch:v1.3.0
        volumeMounts:
        - name: containers
          mountPath: /var/lib/docker/containers
        - name: varlog
          mountPath: /varlog
      volumes:
      - hostPath:
          path: /var/lib/docker/containers
        name: containers
      - hostPath: 
          path: /var/log
        name: varlog
```

### 指定部署节点
在 DaemonSet 中指定节点部署有几种方法：

1. nodeSelector: 使用 nodeSelector 字段可以指定一个或多个节点标签，以确保 DaemonSet 的 Pod 仅部署到具有匹配标签的节点上。

```yaml
spec:
  template:
    spec:
      nodeSelector:
        disk: ssd
```

2. affinity/anti-affinity: 使用 affinity 字段可以根据节点的亲和性或反亲和性进行部署。亲和性可确保一组 Pod 在同一节点上部署，而反亲和性则确保一组 Pod 在不同的节点上部署。

```yaml
spec:
  template:
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: disk
                operator: In
                values:
                - ssd
```

3. nodeSelectorTerms: 在 nodeAffinity 字段中，nodeSelectorTerms 允许您指定多个节点选择器条件。这样可以更灵活地控制 DaemonSet 的 Pod 部署。

```yaml
spec:
  template:
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: disk
                operator: In
                values:
                - ssd
            - matchExpressions:
              - key: gpu
                operator: Exists
```

### 更新策略
推荐使用OnDelete

## HPA
### metrics
> top本身不可用，需要安装这个命令才可以使用
>

在使用 Horizontal Pod Autoscaler (HPA) 之前，您需要确保您的 Kubernetes 集群中已经配置了支持 HPA 所需的度量指标（metrics）。常见的度量指标包括 CPU 利用率和内存利用率。

HPA 支持以下两种类型的度量指标：

1. Resource Metrics：资源度量指标是关于 Pod 的资源使用情况，例如 CPU 利用率和内存利用率。这些度量指标由 Kubernetes 监控系统（如 metrics-server）提供。
2. Custom Metrics：自定义度量指标是您可以根据自己的需求定义的度量指标，例如队列长度、请求速率等。这些度量指标由您自己的监控系统提供，并且需要安装和配置相应的监控适配器，例如 Prometheus 适配器。

```shell
wget https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml -O metrics-server-components.yaml

sed -i "s/k8s.gcr.ioVmetrics-server/registry.cn-hangzhou.aliyuncs.comVgoogle_containers/g' metrics-server-components.yaml

# 去除HTTPS 配置
在containers里面添加
# - --kubelet-insecure-tls

```

### 使用
Horizontal Pod Autoscaler（HPA）是 Kubernetes 中的一种资源，用于根据 CPU 使用率或自定义指标自动调整 Pod 的副本数量，以适应应用程序的负载变化。以下是一个简单的 HPA 的 YAML 示例：

```yaml
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  name: my-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-deployment
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      targetAverageUtilization: 50
```

这个 HPA 的 YAML 文件描述了一个 HorizontalPodAutoscaler 资源，它会自动调整名为 my-deployment 的 Deployment 中 Pod 的副本数量。

+ scaleTargetRef: 指定了要自动扩展的 Deployment 的引用。
+ minReplicas 和 maxReplicas: 指定了 Pod 副本数量的最小值和最大值。
+ metrics: 指定了用于自动扩展的指标。
    - type: Resource: 表示使用资源指标（例如 CPU 使用率）进行自动扩展。
    - resource.name: cpu: 指定了使用 CPU 使用率作为自动扩展的指标。
    - resource.targetAverageUtilization: 50: 指定了目标平均 CPU 利用率为 50%，当 CPU 利用率超过此阈值时，HPA 将增加 Pod 的副本数量。

这个示例中的 HPA 会监视名为 my-deployment 的 Deployment 中 Pod 的 CPU 使用率，并在 CPU 使用率超过 50% 时增加 Pod 的副本数量，最多不超过 10 个，最少不少于 1 个。

```shell
kubectl autoscale deployment <deployment-name> --cpu-percent=80 --min=1 --max=10
```